# Real-Time-Hand-Tracking-and-Gesture-Recognition-using-MediaPipe
This project implements real-time hand tracking and hand gesture recognition using Google's MediaPipe framework. The system accurately detects and tracks hand landmarks in real time, enabling gesture-based interaction. Future updates will extend this work to support VR headsets and Leap Motion devices.
Overview
![hand_tracking_resultU](https://github.com/user-attachments/assets/22649b35-5bf8-424b-998d-ff948318af3e)
![hand_tracking_resultB](https://github.com/user-attachments/assets/2daee80c-7220-4841-b0f0-571595a74718)

# Features

- Real-time Hand Tracking: Utilizes MediaPipe's Hand Tracking module for fast and accurate hand landmark detection.

- Gesture Recognition: Recognizes predefined hand gestures for interaction.

- Scalability: Planned future support for VR headsets and Leap Motion devices.

- Optimized for Performance: Runs efficiently on CPU and GPU for real-time applications.

# Installation

To set up the project, follow these steps:

# Prerequisites

Ensure you have Python installed (preferably Python 3.7+).

# Steps

# Clone the repository
git clone https://github.com/yourusername/mediapipe-hand-tracking.git
cd mediapipe-hand-tracking

# Create a virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`

# Install dependencies
pip install -r requirements.txt

# Usage

Run the hand tracking script using:

python hand_tracking.py

This will open a real-time webcam feed and detect hand landmarks.

# Future Work

- Integration with VR Headsets (Oculus, HTC Vive, etc.)

- Leap Motion Support

- Enhanced Gesture Recognition with Machine Learning

# Contributions

Contributions are welcome! Feel free to fork the repository and submit pull requests.

# License

This project is licensed under the MIT License - see the LICENSE file for details.

# Acknowledgments

- Google MediaPipe Team

- Open-source contributors
